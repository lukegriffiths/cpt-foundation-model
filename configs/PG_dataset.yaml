# --- Paths ---
data_paths:
  input_file: 'data/raw/Database_CPT_PremstallerGeotechnik/CPT_PremstallerGeotechnik_revised.csv'
  processed_dir: 'data/processed/PG'
  scaler_path: 'data/processed/PG/scaler.joblib'
  model_save_path: 'models/foundation_model_PG.pth'

# --- Feature Engineering ---
# Maps your generic feature names to the specific column names in this dataset's CSV
feature_mapping:
  qc: 'qc (MPa)'
  fs: 'fs (kPa)'
  #u2: 'u2 (kPa)'
  #soil_class: 'Oberhollenzer_classes'

# --- Model Hyperparameters ---
model_params:
  num_features: 2 # qc and fs for CPT data
  model_dim: 128  # Reduced from 256 - sufficient for 2 features, faster training
  num_heads: 4    # Reduced from 8 - better for smaller model_dim (128/4=32 head_dim)
  num_layers: 6   # Increased from 4 - CPT sequences need depth for geological patterns
  dropout: 0.15   # Added explicit dropout for regularization

# --- Training Hyperparameters ---
training_params:
  batch_size: 32         # Increased from 16 - leverage GPU memory for faster training
  learning_rate: 0.0002  # Increased from 0.0001 - higher LR with larger batches
  num_epochs: 200        # Reduced from 300 - larger batches train faster
  max_len: 1024          # Increased from 512 - GPU can handle longer sequences
  overlap: 256           # Increased from 128 - better context with longer sequences
  mask_ratio: 0.15       # Reduced from 0.2 - more conservative for better learning
  mask_strategy: 'span'  # Keep span masking - good for sequential data
  mean_span_length: 15   # Reduced from 20 - shorter spans for better reconstruction
  block_size: 8          # Reduced from 10 - smaller blocks for finer granularity
  mask_type: 'noise'     # Keep noise masking - robust for CPT data

# --- Data Splitting Parameters ---
data_split:
  train_ratio: 0.8  # 80% of the data for training
  val_ratio: 0.1    # 10% for validation. The rest (10%) will be for testing.
  random_seed: 42   # Seed for reproducible shuffling